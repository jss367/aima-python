{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Search Approaches\n",
    "\n",
    "If we have outside knowledge about our world, can we apply that knowledge to improve our search algorithms? When we add our own intelligence that's really the guts of third wave AI.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/3rd_wave_elsa.png\">\n",
    "</p>\n",
    "\n",
    "## Greedy Best-first Search\n",
    "So, for example, in the mapping problem in the text\n",
    "suppose we also know (from another source) the point-to-point distances between the cities, independent of roads.\n",
    "<p align=\"center\">\n",
    "<img src=\"images/Romania+with+step+costs+in+km.jpg\">\n",
    "</p>\n",
    "\n",
    "So if I'm in Arad, there are three cities I can choose to go through as I try to find the best route to Bucharest. What's the best choice? What next?\n",
    "\n",
    "It turns out that this greedy best-first algorithm will find a good path, but not quite the best path. But what did this algorithm ignore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A* Search\n",
    "\n",
    "In the past algorithm, we informed the best-search algorithm with our external heuristic $f(n) = h(n)= $ the straight-line distance of city $n$ to Bucharest. But we completely ignored how far each city was from our starting city.\n",
    "\n",
    "Now let's inform the best-search with \n",
    "\\[\n",
    "    f(n) = g(n) + h(n) \n",
    "\\]\n",
    "where $g(n)$ accounts for the travel distance to from the starting city to the frontier city.\n",
    "\n",
    "## What does $h$ have to promise for A* to be cost optimal?\n",
    "\n",
    "The heuristic has to be **admissible**, meaning that it *never overestimates* the distance to the goal.\n",
    "\n",
    "A stronger condition is that a heuristic be **consistent**. Wikipedia gives a nicer explanation than the text:\n",
    "\n",
    "Formally, for every node N and each successor P of N, the estimated cost of reaching the goal from N is no greater than the step cost of getting to P plus the estimated cost of reaching the goal from P. That is:\n",
    "\n",
    "$$ h(N)\\leq c(N,P)+h(P)$$ \n",
    "\n",
    "$$h(G)=0$$\n",
    "where\n",
    "\n",
    "* $h$ is the consistent heuristic function\n",
    "* $N$ is any node in the graph\n",
    "* $P$ is any descendant of $N$\n",
    "* $G$ is any goal node\n",
    "* $c(N,P)$ is the cost of reaching node $P$ from $N$\n",
    "Informally, every node $i$ will give an estimate that, accounting for the cost to reach the next node, is always lesser than the estimate at node $i+1$. (This is the triangle inequality.)\n",
    "\n",
    "Another term for a consistent heuristic is a **monotonic heuristic**.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/romania.jpg\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/astar_buch.jpg\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can A* work faster?\n",
    "\n",
    "As it is, A* has to open all of its subnodes at each step to decide which is best. If two nodes have the same $f(n) = g(n) + h(n)$ then both have to be expanded. How can we adjust this? \n",
    "\n",
    "## Weighted A*\n",
    "\n",
    "What if we decide being closer to the goal is more important than how far we've already traveled? \n",
    "* How far we've traveled is sunk cost at this point in the algorithm.\n",
    "* What we want to do is save computation time and finish this thing.\n",
    "\n",
    "So now states can expanded following the heuristic\n",
    "$$ f(n) = g(n) + W \\times h(n)$$\n",
    "where $W > 1$. It may not give an optimal solution, but it will decide more quickly and the text calls this a **satisficing** \n",
    "solution.\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/astar_v_weighted.png\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory-bounded searches\n",
    "\n",
    "Some quick tricks to reduce the burden on memory:\n",
    "* for a larger problem, don't hold the frontier nodes as reached until done with them on the frontier (but it complicates code)\n",
    "* Keep reference counts for states if we know how many visits we can have to that state before it's not going to offer an optional solution.\n",
    "* **Beam search** only keep the $k$ best-performing nodes in the frontier and throw away the rest. *OR* only keep the nodes that are within $\\delta$ of the best.\n",
    "* **Iterative-deepening A* search (IDA*)** trades off holding visited nodes in memory with the cost of possibly re-visiting nodes that have already been searched. A cutoff-value is determined at each step and any nodes with $f$-values that are higher a discarded, creating a search contour. When the values are floats, this contour may consist of just one node at each step and perhaps too much information is lost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at good slides from the University of Cambridge https://www.cl.cam.ac.uk/teaching/0809/ArtIntI/notes2.pdf\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"images/ida0.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/ida1.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/ida2.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/ida3.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **Recursive best-first search (RBFS)** starts to act like a recursive depth-first search, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_first_recursive_search(problem, node=None):\n",
    "    if node is None: \n",
    "        node = Node(problem.initial)\n",
    "    if problem.is_goal(node.state):\n",
    "        return node\n",
    "    elif is_cycle(node):\n",
    "        return failure\n",
    "    else:\n",
    "        for child in expand(problem, node):\n",
    "            result = depth_first_recursive_search(problem, child)\n",
    "            if result:\n",
    "                return result\n",
    "        return failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recursive_best_first_search(problem, h=None):\n",
    "    \"\"\"[Figure 3.26]\"\"\"\n",
    "    # This caches h values on the nodes and can be\n",
    "    # examined on the returned path\n",
    "    h = memoize(h or problem.h, 'h')\n",
    "\n",
    "    def RBFS(problem, node, flimit):\n",
    "        # are you at your goal?\n",
    "        if problem.goal_test(node.state):\n",
    "            return node, 0  # (The second value is immaterial)\n",
    "        # What's the frontier\n",
    "        successors = node.expand(problem)\n",
    "        # If I'm on a leaf and didn't solve the problem return horrible score\n",
    "        # that allows us to look somewhere else\n",
    "        if len(successors) == 0:\n",
    "            return None, np.inf\n",
    "        for s in successors:\n",
    "            # each node's new cost is the path_cost to get there plus\n",
    "            # the heuristic guess, or it's current f val, whichever is worse\n",
    "            s.f = max(s.path_cost + h(s), node.f)\n",
    "        while True:\n",
    "            # Order by lowest f value\n",
    "            successors.sort(key=lambda x: x.f)\n",
    "            best = successors[0]\n",
    "            # I can't search the successors if the best\n",
    "            # is over the limit\n",
    "            if best.f > flimit:\n",
    "                return None, best.f\n",
    "            # If there are choices record alt value\n",
    "            if len(successors) > 1:\n",
    "                alternative = successors[1].f\n",
    "            else:\n",
    "                alternative = np.inf\n",
    "            # Here's where the cutoff is set\n",
    "            result, best.f = RBFS(problem, best, min(flimit, alternative))\n",
    "            if result is not None:\n",
    "                return result, best.f\n",
    "\n",
    "    node = Node(problem.initial)\n",
    "    node.f = h(node)\n",
    "    result, bestf = RBFS(problem, node, np.inf)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs0.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs1.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs2.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs3.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs4.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rbfs5.png\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "<img src=\"images/rfbs_bucharest.jpg\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is this throwing the baby out with the bath water?\n",
    "<img src=\"images/babu.png\" width=300>\n",
    "\n",
    "By remembering **nothing** we had to retrace steps. __MA*, memory bounded A*__ and it's friendly cousin __SMA*__ (Simplified...) expands until the memory is full. SMA* just drops the worst lef at this time and then backs up teh value of the forgotten node to its parent. So it's only going back to that subtree if it's desperate. Problems that require high memory resources can be theoretically solvable by A* but stuck in a _trashing_ pattern or having to repeatedly regenerate nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 Heuristic Functions\n",
    "\n",
    "How important is the accuracy of your heuristic? Example: 8-puzzle\n",
    "\n",
    "\n",
    "\n",
    "![](https://ece.uwaterloo.ca/~dwharder/aads/Algorithms/N_puzzles/images/puz3.png)\n",
    "\n",
    "The goal here is to get to\n",
    "\n",
    "![](https://ece.uwaterloo.ca/~dwharder/aads/Algorithms/N_puzzles/images/puz1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what kind of metrics could we assign the top-left puzzle?\n",
    "* The **Hamming Distance** is the number of wrong tiles (8 for this guy, and 7 for the top-right).\n",
    "* The **Manhattan Distance** is the sum of the distances of the tiles to get to the right place -- so are the tiles a little bit wrong or a lot wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(nodes, goals):\n",
    "    X = (0, 1, 2, 0, 1, 2, 0, 1, 2)\n",
    "    Y = (0, 0, 0, 1, 1, 1, 2, 2, 2)\n",
    "    return sum(abs(X[s] - X[g]) + abs(Y[s] - Y[g])\n",
    "                for (s, g) in zip(nodes, goals) if s != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan((5,2,7,8,4,0,1,3,6), (1,2,3,4,5,6,7,8,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 0 + 4 + 2 + 1  + 2 + 3 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't get the same answer for the example in the text, either, but we get the basic idea. The book discusses metrics that are good for performance comparisons. the *effective branching factor* and *effective depth* are determined determining how a uniform tree of depth $d$ would have to be constructed to reflect the number of nodes that were expanded in the search. But for us I think it's sufficient to note the number of nodes expanded by each approach.\n",
    "\n",
    "| $d$ |    BFS  |   A*($h_1$) | A*($h_2$) |\n",
    "| ---| -----| -------| -----|\n",
    "| 2  |     5   |   6  |    6  |\n",
    "| 4 |     33 |    12 |    12 | 2.06  1.49  1.49\n",
    "| 6 |    128 |    24 |    19 | 2.01  1.42  1.34\n",
    "| 8 |    368 |    48 |    31 | 1.91  1.40  1.30\n",
    "|10 |   1033 |   116 |    48 | 1.85  1.43  1.27\n",
    "|12 |   2672 |   279 |    84 | 1.80  1.45  1.28\n",
    "|14 |   6783 |   678 |   174 | 1.77  1.47  1.31\n",
    "|16 |  17270 |  1683 |   364 | 1.74  1.48  1.32\n",
    "|18 |  41558 |  4102 |   751 | 1.72  1.49  1.34\n",
    "|20 |  91493 |  9905 |  1318 | 1.69  1.50  1.34\n",
    "|22 | 175921 | 22955 |  2548 | 1.66  1.50  1.34\n",
    "|24 | 290082 | 53039 |  5733 | 1.62  1.50  1.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When one heuristic is always better than another, we say that it (e.g. $h_2$) **dominates** the other (e.g. $h_1$)\n",
    "\n",
    "## Relaxed problems\n",
    "\n",
    "One way to generate heuristics is to change your problem to a more _relaxed_ problem -- one with fewer rules. \n",
    "* The Manhattan distance pretends you can just slam a tile into another tile\n",
    "* The Romanian heuristic assumed you could just fly like a bird.\n",
    "\n",
    "*ABSolver* (1990's) can find useful heuristics for this problem as well as rubics cube etc.\n",
    "\n",
    "## Other ways to generate better heuristics\n",
    "\n",
    "* Create **pattern databases** that store the exact solution costs for every possible subproblem. I personally think this is cheating. But it actually does let you solve the problem very quickly. \n",
    "* Clever ppl can combine disjoint puzzle databases to solve the 15-puzzle quickly.\n",
    "\n",
    "* **Landmarks** are things that every plan for a task must eventually satisfy. You calculate the exact costs between each landmarks and the other nodes:\n",
    "$$h_L(n) = \\min_{L \\in \\texttt{Landmarks}} C^*(n,L) + C^*(L, \\texttt{goal})$$\n",
    "It turns out that this isn't quite admissible, although it is efficient. However, the associated **differential heuristic** is admissible:\n",
    "$$ h_{DH}(n) = \\max_{L\\in\\texttt{Landmarks}} | C^*(n,L) - C^*(\\texttt{goal}, L)|$$\n",
    "This works because the most useful landmarks are over-estimates. This difference gives us an estimate for the distance to the goal if any of the landmarks over-shoot our goal.\n",
    "\n",
    "## But this is an AI book so can't we learn how to search better?\n",
    "\n",
    "Yes. Each state in a **metalevel state space** captures the computational state of a program that's searching the original object-level state space. So maybe we'll get into this once we really learn reinforcement learning.\n",
    "\n",
    "Also, we could take a bunch of randomly generated problem instances and collect statistics about solution costs. Then we could create a machine learning model that predicts costs given state information and use that as a heuristic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ec332c3762279bf04c318127bba8846de175531a02d6981c60e86e990426d1b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('aibc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
